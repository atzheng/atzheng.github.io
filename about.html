<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-07-31 Mon 10:31 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>About me</title>
<meta name="author" content="Andrew Zheng" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="./tufte-css/tufte.css"/>
<link rel="stylesheet" type="text/css" href="./style.css"/>
</head>
<body>
<div id="content" class="content">
<div class="SIDEBAR" id="org8921ea4">

<div id="org958d1ee" class="figure">
<p><img src="profile.jpg" alt="profile.jpg" width="65%" /><br />
</p>
</div>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgabdca02">About me</a></li>
<li><a href="#org1f2409b">Publications</a></li>
<li><a href="#org384f178">Teaching</a></li>
</ul>
</div>
</div>

</div>
<hr />
<div id="outline-container-orgabdca02" class="outline-2">
<h2 id="orgabdca02">About me</h2>
<div class="outline-text-2" id="text-orgabdca02">
<p>
In 2024, I&rsquo;ll be starting as an assistant professor in <a href="https://www.sauder.ubc.ca/thought-leadership/divisions/operations-and-logistics">Operations and Logistics</a> at UBC Sauder.  I&rsquo;m interested in experimentation and control problems in marketplace settings, specifically challenges relating to interference, sequential designs, policy evaluation, and policy optimization.<br />
</p>

<p>
I completed my PhD at the Operations Research Center at MIT, advised by Prof. <a href="http://web.mit.edu/vivekf/www/">Vivek Farias</a>. Previously, I was a data scientist at Uber, working on match optimization for UberPOOL. I received my B.S. in Industrial Engineering and M.S. in Computer Science at Northwestern University. You can find my full CV <a href="cv.pdf">here</a>.<br />
</p>

<p>
In my spare time I play jazz, look for birds, and procrastinate by tweaking my Emacs config or the CSS on this site.<br />
</p>

<hr />
</div>
</div>

<div id="outline-container-org1f2409b" class="outline-2">
<h2 id="org1f2409b">Publications</h2>
<div class="outline-text-2" id="text-org1f2409b">
<ul class="org-ul">
<li><b><a href="https://arxiv.org/abs/2305.02542">Correcting for Interference in Experiments: A Case Study at Douyin</a></b><br />
<i>with Vivek Farias, Hao Li, Tianyi Peng, Xinyuyang Ren, and Huawei Zhang</i><br />
Preliminary: RecSys 2023.<br />
   <details><summary>Details</summary><br />
  Interference is a ubiquitous problem in experiments conducted on two-sided content marketplaces, such as Douyin (China&rsquo;s analog of TikTok). In many cases, creators are the natural unit of experimentation, but creators interfere with each other through competition for viewers&rsquo; limited time and attention. &ldquo;Naive&rdquo; estimators currently used in practice simply ignore the interference, but in doing so incur bias on the order of the treatment effect. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, are impractically high variance. We introduce a novel Monte-Carlo estimator, based on &ldquo;Differences-in-Qs&rdquo; (DQ) techniques, which achieves bias that is second-order in the treatment effect, while remaining sample-efficient to estimate. On the theoretical side, our contribution is to develop a generalized theory of Taylor expansions for policy evaluation, which extends DQ theory to all major MDP formulations. On the practical side, we implement our estimator on Douyin&rsquo;s experimentation platform, and in the process develop DQ into a truly &ldquo;plug-and-play&rdquo; estimator for interference in real-world settings: one which provides robust, low-bias, low-variance treatment effect estimates; admits computationally cheap, asymptotically exact uncertainty quantification; and reduces MSE by 99\% compared to the best existing alternatives in our applications.<br />
   </details><br /></li>
<li><p>
<b><a href="papers/markovian-interference.pdf">Markovian Interference in Experiments</a></b><br />
<i>with Vivek Farias, Andrew A. Li, and Tianyi Peng.</i><br />
Preliminary: NeurIPS 2022. Under preparation for Management Science.<br />
</p>
<div class="awards" id="org5e76750">
<ul class="org-ul">
<li><b>Winner</b>, 2022 RMP Jeff McGill Student Paper Award.<br /></li>
<li><b>Winner</b>, 2022 APS Best Student Paper Award.<br /></li>
<li><b>Oral</b> presentation at NeurIPS 2022.<br /></li>
</ul>

</div>
<p>
   <details><summary>Details</summary><br />
We model experimentation in marketplace settings as an <i>off-policy evaluation</i> (OPE) problem. On one hand, &ldquo;naive&rdquo; A/B testing suffers bias on the order of the treatment effect; on the other, unbiased OPE estimators suffer from extremely high variance. We develop a bias-corrected estimator with bias <i>second-order</i> in the treatment effect, and variance exponentially smaller than unbiased OPE. This estimator dramatically improves over alternatives, even in our experiments on a large-scale ridesharing simulator. This correction is derived from a Taylor-like expansion of the off-policy objective value, of independent interest.<br />
   </details><br />
</p></li>
<li><b><a href="papers/synthetically-controlled-bandits.pdf">Synthetically Controlled Bandits</a></b><br />
 <i>with Vivek Farias, Ciamac Moallemi, and Tianyi Peng.</i><br />
 Preliminary: MSOM Service Management SIG 2022. Major revision, submitted to Management Science.<br />
 <details><summary>Details</summary><br />
Synthetic controls are commonly used to control for non-stationarity, but the fixed experimental designs typical in such settings are both costly and fragile to non-stationarity in the controls. By instead designing experiments <i>adaptively</i>, we can robustly identify the optimal treatment while incurring low regret.<br />
   </details><br /></li>
<li><b><a href="papers/limits-to-learning.pdf">The Limits to Learning a Diffusion Process</a></b><br />
<i>with Jackie Baek, Vivek Farias, Andreea Georgescu, Retsef Levi, Tianyi Peng, Deeksha Sinha, and Joshua Wilde.</i><br />
Preliminary: EC 2021. Major revision, submitted to Management Science.<br />
 <details><summary>Details</summary><br />
Diffusion processes model viral transmission in a population. Two classic examples are the SIR model for disease transmission, and the Bass model for product adoption. We present a Cramer-Rao bound characterizing the difficulty of learning such models in a stochastic setting. Key parameters <i>cannot</i> be learned with reasonable variance until 2/3 of the time where infections (or product adoptions) are at their peak, a major barrier to timely pandemic response. In practice, we work around this via a regularization approach based on geographic heterogeneity, and apply this approach to predicting the spread of COVID-19.<br />
 </details><br /></li>
<li><b><a href="https://www.pnas.org/doi/10.1073/pnas.2113561119">Evaluation of individual and ensemble probabilistic forecasts of COVID-19 mortality in the US</a></b><br />
<i>with Estee Cramer et. al.</i><br />
PNAS 2022<br /></li>
<li><b><a href="papers/optimizing-offer-sets.pdf">Optimizing Offer Sets in Sublinear Time</a></b><br />
 <i>with Vivek Farias, Andrew A. Li, and Deeksha Sinha.</i><br />
 Preliminary: EC 2020. Minor revision, submitted to Management Science.<br />
 <details><summary>Details</summary><br />
 Online retailers must be able to serve high-quality product assortments within milliseconds of a request. At a scale of millions of products and users, this necessitates approaches to assortment optimization that work in time <i>sub-linear</i> in the number of products. We design a sampling scheme, based on locality-sensitive hashing, which samples a set of candidate products which is 1) sub-linear in size, and 2) contains a provable approximation to the optimal assortment. Experiments show show a much better tradeoff between response time and optimality, relative to existing heuristics.<br />
   </details><br /></li>
<li><b><a href="papers/kernel-alp.pdf">Non-parametric Approximate Dynamic Programming via the Kernel Method</a></b><br />
<i>with Nikhil Bhat, Vivek Farias, and Ciamac Moallemi.</i><br />
Accepted in Stochastic Systems.<br />
  <details><summary>Details</summary><br />
 A novel, non-parametric approximate dynamic programming (ADP) algorithm that enjoys dimension-independent approximation and sample complexity guarantees. We obtain this algorithm by ‘kernelizing’ a recent mathematical program for ADP, the &ldquo;smoothed approximate LP&rdquo;.<br />
   </details><br /></li>
</ul>

<hr />
</div>
</div>

<div id="outline-container-org384f178" class="outline-2">
<h2 id="org384f178">Teaching</h2>
<div class="outline-text-2" id="text-org384f178">
<ul class="org-ul">
<li><b>15.778: Introduction to Operations Management</b><br />
<i>Summer 2020, 2021, 2022, TA</i><br />
 Inventory management, queueing, capacity analysis. Core class for the Sloan Fellows MBA program for mid-career professionals. Developed an interactive <a href="https://atzheng.shinyapps.io/retailer-game/">revenue management</a> game, now also used at several other universities.<br /></li>
</ul>


<ul class="org-ul">
<li><b>15.003: Analytics Tools</b><br />
<i>Fall 2019, 2021, Instructor</i><br />
 Data science tools in R and Python, for the Masters of Business Analytics program.<br /></li>
</ul>

<ul class="org-ul">
<li><b><a href="https://philchodrow.github.io/cos_2018/">Computing in Optimization and Statistics</a></b><br />
<i>IAP 2018, Instructor</i><br />
 Data science tools in R and Python, for MIT graduate and undergraduate students.<br /></li>
</ul>
</div>
</div>
</div>
</body>
</html>